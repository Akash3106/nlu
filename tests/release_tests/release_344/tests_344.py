import unittest
import nlu
import sys


class Test344(unittest.TestCase):

    def test_344_models(self):
        import pandas as pd
        te = [
            # 'en.ner.debertav3_large.conll03',
            # 'en.ner.debertav3_base.conll03',
            # 'en.ner.debertav3_small.conll03',
            # 'en.ner.debertav3_xsmall.conll03',
            # 'en.ner.debertav3_large.ontonotes',
            # 'en.ner.debertav3_base.ontonotes',
            # 'en.ner.debertav3_small.ontonotes',
            # 'en.ner.debertav3_xsmall.ontonotes',
            # 'fr.embed.camembert_large',
            # 'fr.embed.camembert_base',
            # 'fr.embed.camembert_ccnet4g',
            # 'fr.embed.camembert_base_ccnet',
            # 'fr.embed.camembert_oscar_4g',
            # 'fr.embed.camembert_wiki_4g',
            # 'fr.embed.albert',
            # 'fr.embed.distilbert',
            # 'mr.embed.distilbert',
            # 'mr.embed.albert',
            # 'id.embed.distilbert',
            # 'ar.embed.distilbert',
            # 'ar.embed.albert',
            # 'fa.embed.albert',
            # 'mr.embed.albert',
            # 'jv.embed.distilbert',
            # 'ms.embed.albert',
            # 'ms.embed.distilbert',
            #
            #
            #
            # 'en.med_ner.biomedical_bc2gm', # OK?
            # 'en.resolve.rxnorm_action_treatment', # OK?
            # 'pt.med_ner.deid.subentity',
            # 'pt.med_ner.deid.generic',
            # 'pt.med_ner.deid',
            # BATCH 2
            # 'bn.embed.indic_transformers_bn_distilbert' ,
            # 'de.embed.distilbert_base_de_cased' ,
            # 'de.embed.distilbert_base_german_cased' ,
            # 'de.embed.albert_german_ner' ,
            # 'en.embed.albert_xlarge_v1' ,
            # 'en.embed.albert_base_v1' ,
            # 'en.embed.albert_xxlarge_v1' ,
            # 'en.embed.distilbert_base_en_cased' ,
            # 'en.embed.distilbert_base_uncased_sparse_90_unstructured_pruneofa' ,
            # 'en.embed.distilbert_base_uncased_sparse_85_unstructured_pruneofa' ,
            # 'es.embed.distilbert_base_es_multilingual_cased' ,
            # 'es.embed.distilbert_base_es_cased' ,
            # 'fa.embed.distilbert_fa_zwnj_base' ,
            # 'hi.embed.distilbert_base_hi_cased' ,
            # 'hi.embed.indic_transformers_hi_distilbert' ,
            # 'it.embed.distilbert_base_it_cased' ,
            # 'it.embed.BERTino' ,
            # 'ja.embed.distilbert_base_ja_cased' ,
            # 'ja.embed.albert_base_japanese_v1' ,
            # 'nl.embed.distilbert_base_cased' ,
            # 'pl.embed.distilbert_base_cased' ,
            # 'ro.embed.distilbert_base_cased' ,
            # 'ro.embed.ALR_BERT' ,
            # 'th.embed.distilbert_base_cased' ,
            # 'tr.embed.distilbert_base_cased' ,
            # 'uk.embed.distilbert_base_cased' ,
            # 'ur.embed.distilbert_base_cased' ,
            # 'zh.embed.distilbert_base_cased' ,
            # 'ar.embed.albert_xlarge_arabic' ,
            # 'ar.embed.albert_large_arabic' ,
            # 'fa.embed.albert_fa_zwnj_base_v2' ,
            # 'mr.embed.marathi_albert_v2' ,
            # 'ms.embed.albert_tiny_bahasa_cased' ,
            # 'ms.embed.albert_base_bahasa_cased' ,
            # 'pt.embed.distilbert_base_cased' ,
            # 'jv.embed.javanese_distilbert_small_imdb' ,
            # 'ru.embed.distilbert_base_cased' ,

            # 'mr.embed.albert_v2',

            # 'en.classify.questionpair',
            # 'en.classify.question_vs_statement',
            # 'en.classify.song_lyrics',
            # 'af.embed.w2v_cc_300d',
            # 'af.stopwords',
            # 'als.embed.w2v_cc_300d',
            # 'am.embed.w2v_cc_300d',
            # 'am.embed.am_roberta',
            # 'am.stopwords',
            # 'an.embed.w2v_cc_300d',
            # 'ar.pos.arabic_camelbert_msa_pos_msa',
            # 'ar.pos.arabic_camelbert_mix_pos_egy',
            # 'ar.pos.arabic_camelbert_da_pos_glf',
            # 'ar.pos.arabic_camelbert_ca_pos_glf',
            # 'ar.pos.arabic_camelbert_msa_pos_egy',
            # 'ar.pos.arabic_camelbert_ca_pos_egy',
            # 'ar.pos.arabic_camelbert_msa_pos_glf',
            # 'ar.pos.arabic_camelbert_mix_pos_glf',
            # 'ar.pos.arabic_camelbert_da_pos_egy',
            # 'ar.stopwords',
            # 'ar.embed.multi_dialect_bert_base_arabic',
            # 'ar.ner.arabic_camelbert_da_ner',
            # 'ar.ner.arabic_camelbert_mix_ner',
            # 'ar.pos',
            # 'ar.ner.multilingual_cased_ner_hrl',
            # 'ar.ner.arabic_camelbert_msa_ner',
            # 'ar.ner.ANER',
            # 'ar.ner.arabert_ner',
            # 'ar.lemma',
            # 'ar.pos.arabic_camelbert_mix_pos_msa',
            # 'ar.embed.mbert_ar_c19',
            # 'ar.embed.bert_base_arabic_camelbert_msa_half',
            # 'ar.embed.bert_large_arabertv02',
            # 'ar.embed.AraBertMo_base_V1',
            # 'ar.embed.DarijaBERT',
            # 'ar.embed.bert_base_arabertv02',
            # 'ar.embed.arabert_c19',
            # 'ar.embed.bert_base_arabic_camelbert_msa',
            # 'ar.embed.bert_base_arabertv2',
            # 'ar.embed.bert_base_arabic',
            # 'ar.embed.Ara_DialectBERT',
            # 'ar.embed.MARBERT',
            # 'ar.embed.bert_base_arabic_camelbert_msa_eighth',
            # 'ar.embed.MARBERTv2',
            # 'ar.embed.bert_large_arabertv2',
            # 'ar.embed.bert_base_arabert',
            # 'ar.embed.bert_base_arabertv01',
            # 'ar.embed.bert_mini_arabic',
            # 'ar.embed.bert_large_arabic',
            # 'ar.embed.bert_large_arabertv02_twitter',
            # 'ar.embed.dziribert',
            # 'ar.embed.bert_base_arabertv02_twitter',
            # 'ar.embed.bert_medium_arabic',
            # 'ar.pos.arabic_camelbert_da_pos_msa',
            # 'ar.embed.bert_base_qarib',
            # 'ar.embed.bert_base_qarib60_860k',
            # 'ar.embed.bert_base_qarib60_1790k',
            # 'ar.embed.bert_base_arabic_camelbert_msa_sixteenth',
            # 'ar.embed.bert_base_arabic_camelbert_mix',
            # 'ar.embed.bert_base_arabic_camelbert_msa_quarter',
            # 'arz.embed.w2v_cc_300d',
            # 'as.embed.w2v_cc_300d',
            # 'ast.embed.w2v_cc_300d',
            # 'az.embed.w2v_cc_300d',
            # 'az.stopwords',
            # 'ba.embed.w2v_cc_300d',
            # 'bar.embed.w2v_cc_300d',
            # 'bcl.embed.w2v_cc_300d',
            # 'be.embed.w2v_cc_300d',
            # 'be.lemma',
            # 'bg.embed.w2v_cc_300d',
            # 'bg.stopwords',
            # 'bh.embed.w2v_cc_300d',
            # 'bn.embed.w2v_cc_300d',
            # 'bn.embed.indic_transformers_bn_bert',
            # 'bn.embed.muril_adapted_local',
            # 'bn.embed.bangla_bert',
            # 'bn.stopwords',
            # 'bpy.embed.w2v_cc_300d',
            # 'br.embed.w2v_cc_300d',
            # 'ca.lemma',
            # 'ca.embed.w2v_cc_300d',
            # 'ca.stopwords',
            # 'ce.embed.w2v_cc_300d',
            # 'ceb.embed.w2v_cc_300d',
            # 'co.embed.w2v_cc_300d',
            # 'cop.pos',
            # 'cs.stopwords',
            # 'cs.embed.w2v_cc_300d',
            # 'cs.pos',
            # 'cs.lemma',
            # 'cs.lemma',
            # 'cs.lemma',
            # 'cu.pos',
            # 'cv.embed.w2v_cc_300d',
            # 'da.embed.w2v_cc_300d',
            # 'da.lemma',
            # 'da.stopwords',
            # 'de.embed.bert_base_historical_german_rw_cased',
            # 'de.embed.gbert_base',
            # 'de.embed.german_financial_statements_bert',
            # 'de.stopwords',
            # 'de.lemma',
            # 'de.embed.bert_base_german_dbmdz_uncased',
            # 'de.embed.roberta_base_wechsel_german',
            # 'de.embed.gbert_large',
            # 'de.embed.bert_base_5lang_cased',
            # 'de.embed.bert_base_german_cased_oldvocab',
            # 'de.embed.bert_base_de_cased',
            # 'de.embed.bert_base_german_uncased',
            # 'de.embed.bert_base_german_dbmdz_cased',
            # 'dv.embed.w2v_cc_300d',
            # 'el.stopwords',
            # 'eml.embed.w2v_cc_300d',
            # 'en.embed.muppet_roberta_base',
            # 'en.embed.muppet_roberta_large',
            # 'en.embed.fairlex_ecthr_minilm',
            # 'en.embed.distilroberta_base_finetuned_jira_qt_issue_titles_and_bodies',
            # 'en.embed.legal_roberta_base',
            # 'en.embed.distilroberta_base',
            # 'en.embed.pmc_med_bio_mlm_roberta_large',
            # 'en.lemma',
            # 'en.lemma',
            # 'en.lemma',
            # 'en.embed.roberta_pubmed',
            # 'en.embed.fairlex_scotus_minilm',
            # 'en.embed.distilroberta_base_finetuned_jira_qt_issue_title',
            # 'en.embed.chEMBL26_smiles_v2',
            # 'en.embed.SecRoBERTa',
            # 'en.embed.distilroberta_base_climate_d_s',
            # 'en.embed.chEMBL_smiles_v1',
            # 'en.embed.distilroberta_base_climate_f',
            # 'en.embed.distilroberta_base_climate_d',
            # 'en.embed.Bible_roberta_base',
            # 'en.embed.w2v_cc_300d',
            # 'en.pos',
            # 'en.ner.ner_chemical_bionlp_bc5cdr_pubmed',
            # 'en.pos.roberta_large_english_upos',
            # 'en.ner.roberta_ticker',
            # 'en.embed.bert_political_election2020_twitter_mlm',
            # 'en.embed.bert_base_uncased_mnli_sparse_70_unstructured_no_classifier',
            # 'en.embed.crosloengual_bert',
            # 'en.embed.chemical_bert_uncased',
            # 'en.embed.deberta_base_uncased',
            # 'en.embed.bert_base_en_cased',
            # 'en.embed.bert_for_patents',
            # 'en.embed.SecBERT',
            # 'en.embed.bert_base_5lang_cased',
            # 'en.embed.DiLBERT',
            # 'en.embed.FinancialBERT',
            # 'en.embed.false_positives_scancode_bert_base_uncased_L8_1',
            # 'en.embed.legal_bert_small_uncased',
            # 'en.embed.legal_bert_base_uncased',
            # 'en.embed.COVID_SciBERT',
            # 'en.embed.e',
            # 'en.embed.danbert_small_cased',
            # 'en.embed.bert_base_uncased_dstc9',
            # 'en.embed.hateBERT',
            # 'en.embed.childes_bert',
            # 'en.embed.clinical_pubmed_bert_base_512',
            # 'en.embed.netbert',
            # 'en.embed.psych_search',
            # 'en.embed.muril_adapted_local',
            # 'en.embed.finbert_pretrain_yiyanghkust',
            # 'en.embed.lic_class_scancode_bert_base_cased_L32_1',
            # 'en.embed.sec_bert_sh',
            # 'en.embed.sec_bert_num',
            # 'en.embed.finest_bert',
            # 'en.embed.bert_large_cased_whole_word_masking',
            # 'en.embed.clinical_pubmed_bert_base_128',
            # 'en.embed.bert_base_uncased_sparse_70_unstructured',
            # 'en.embed.sec_bert_base',
            # 'en.stopwords',
            # 'en.embed.agriculture_bert_uncased',
            # 'en.embed.bert_large_uncased_whole_word_masking',
            # 'en.embed.ge',
            # 'en.ner.roberta_large_finetuned_abbr',
            # 'en.ner.roberta_classics_ner',
            # 'en.pos.roberta_base_english_upos',
            # 'en.ner.roberta_large_ner_english',
            # 'en.ner.ner_gene_dna_rna_jnlpba_pubmed',
            # 'en.ner.ner_disease_ncbi_bionlp_bc5cdr_pubmed',
            # 'eo.embed.w2v_cc_300d',
            # 'es.embed.bertin_base_gaussian',
            # 'es.embed.bertin_roberta_base_spanish',
            # 'es.embed.bertin_roberta_large_spanish',
            # 'es.embed.bertin_base_stepwise',
            # 'es.embed.dpr_spanish_passage_encoder_allqa_base',
            # 'es.embed.dpr_spanish_question_encoder_allqa_base',
            # 'es.embed.beto_gn_base_cased',
            # 'es.embed.dpr_spanish_passage_encoder_squades_base',
            # 'es.embed.dpr_spanish_question_encoder_squades_base',
            # 'es.embed.bert_base_es_cased',
            # 'es.embed.bert_base_5lang_cased',
            # 'es.embed.alberti_bert_base_multilingual_cased',
            # 'es.embed.roberta_base_bne',
            # 'es.embed.jurisbert',
            # 'es.embed.mlm_spanish_roberta_base',
            # 'es.embed.roberta_large_bne',
            # 'es.pos',
            # 'es.embed.bertin_base_random_exp_512seqlen',
            # 'es.embed.bertin_base_gaussian_exp_512seqlen',
            # 'es.ner.roberta_base_bne_capitel_ner_plus',
            # 'es.ner.roberta_base_bne_capitel_ner',
            # 'es.ner.RuPERTa_base_finetuned_ner',
            # 'es.pos.roberta_base_bne_capitel_pos',
            # 'es.ner.NER_LAW_MONEY4',
            # 'es.pos.roberta_large_bne_capitel_pos',
            # 'es.ner.bsc_bio_ehr_es_pharmaconer',
            # 'es.embed.RoBERTalex',
            # 'es.ner.roberta_large_bne_capitel_ner',
            # 'es.embed.RuPERTa_base',
            # 'es.embed.bertin_base_random',
            # 'es.lemma',
            # 'es.stopwords',
            # 'es.pos.RuPERTa_base_finetuned_pos',
            # 'es.embed.bertin_base_stepwise_exp_512seqlen',
            # 'es.ner.bsc_bio_ehr_es_cantemist',
            # 'et.stopwords',
            # 'et.pos',
            # 'et.embed.w2v_cc_300d',
            # 'et.lemma',
            # 'et.lemma',
            # 'eu.stopwords',
            # 'eu.embed.w2v_cc_300d',
            # 'eu.lemma',
            # 'fa.embed.roberta_fa_zwnj_base',
            # 'fa.ner.roberta_fa_zwnj_base_ner',
            # 'fa.pos',
            # 'fa.stopwords',
            # 'fi.embed.w2v_cc_300d',
            # 'fi.pos',
            # 'fi.lemma',
            # 'fi.stopwords',
            # 'fi.lemma',
            # 'fo.pos',
            # 'fr.embed.bert_base_fr_cased',
            # 'fr.pos',
            # 'fr.pos',
            # 'fr.embed.french_roberta',
            # 'fr.lemma',
            # 'fr.lemma',
            # 'fr.stopwords',
            # 'fr.embed.roberta_base_wechsel_french',
            # 'frr.embed.w2v_cc_300d',
            # 'fy.embed.w2v_cc_300d',
            # 'ga.pos',
            # 'ga.stopwords',
            # 'gd.embed.w2v_cc_300d',
            # 'gl.embed.w2v_cc_300d',
            # 'gl.lemma',
            # 'gom.embed.w2v_cc_300d',
            # 'grc.lemma',
            # 'grc.stopwords',
            # 'grc.lemma',
            # 'grc.pos',
            # 'gu.embed.RoBERTa_hindi_guj_san',
            # 'gu.stopwords',
            # 'gv.embed.w2v_cc_300d',
            # 'he.stopwords',
            # 'hi.stopwords',
            # 'hi.embed.RoBERTa_hindi_guj_san',
            # 'hi.embed.indic_transformers_hi_roberta',
            # 'hi.embed.muril_adapted_local',
            # 'hi.embed.indic_transformers_hi_bert',
            # 'hr.embed.w2v_cc_300d',
            # 'hr.stopwords',
            # 'hr.lemma',
            # 'hsb.embed.w2v_cc_300d',
            # 'hu.lemma',
            # 'hu.stopwords',
            # 'hy.stopwords',
            # 'hy.lemma',
            # 'hy.embed.w2v_cc_300d',
            # 'hyw.pos',
            # 'hyw.lemma',
            # 'id.pos',
            # 'id.embed.indo_roberta_small',
            # 'id.embed.indonesian_roberta_base',
            # 'id.pos.indonesian_roberta_base_posp_tagger',
            # 'id.lemma',
            # 'id.lemma',
            # 'id.embed.roberta_base_indonesian_522M',
            # 'id.stopwords',
            # 'id.embed.indonesian_roberta_large',
            # 'is.lemma',
            # 'is.stopwords',
            # 'it.stopwords',
            # 'it.pos',
            # 'it.embed.bert_base_italian_xxl_cased',
            # 'it.embed.bert_base_italian_xxl_uncased',
            # 'it.embed.chefberto_italian_cased',
            # 'it.embed.hseBert_it_cased',
            # 'it.embed.wineberto_italian_cased',
            # 'it.pos',
            # 'it.lemma',
            # 'it.lemma',
            # 'it.lemma',
            # 'ja.embed.bert_base_ja_cased',
            # 'ja.embed.bert_base_japanese_char_v2',
            # 'ja.embed.bert_base_japanese_char_extended',
            # 'ja.embed.bert_large_japanese_char',
            # 'ja.embed.bert_large_japanese',
            # 'ja.embed.bert_small_japanese',
            # 'ja.embed.bert_large_japanese_char_extended',
            # 'ja.pos',
            # 'ja.embed.bert_small_japanese_fin',
            # 'ja.embed.bert_base_japanese_basic_char_v2',
            # 'ja.stopwords',
            # 'ja.embed.bert_base_japanese_char_whole_word_masking',
            # 'ja.embed.bert_base_japanese_char',
            # 'ja.embed.bert_base_japanese_whole_word_masking',
            # 'ja.embed.bert_base_japanese_v2',
            # 'jv.embed.javanese_roberta_small',
            # 'jv.embed.javanese_roberta_small_imdb',
            # 'jv.embed.javanese_bert_small_imdb',
            # 'jv.embed.javanese_bert_small',
            # 'ka.embed.w2v_cc_300d',
            # 'kn.embed.KNUBert',
            # 'kn.embed.KanBERTo',
            # 'kn.stopwords',
            # 'ko.lemma',
            # 'ko.stopwords',
            # 'ko.embed.roberta_ko_small',
            # 'ko.pos',
            # 'ko.embed.bert_kor_base',
            # 'ko.embed.dbert',
            # 'ko.embed.KR_FinBert',
            # 'ko.embed.bert_base_v1_sports',
            # 'ko.lemma',
            # 'ky.stopwords',
            # 'la.lemma',
            # 'la.lemma',
            # 'la.pos',
            # 'la.pos',
            # 'lb.stopwords',
            # 'lb.lemma',
            # 'lb.embed.w2v_cc_300d',
            # 'lij.stopwords',
            # 'lmo.embed.w2v_cc_300d',
            # 'lt.embed.w2v_cc_300d',
            # 'lt.lemma',
            # 'lt.stopwords',
            # 'lv.stopwords',
            # 'lv.pos',
            # 'mai.embed.w2v_cc_300d',
            # 'mg.embed.w2v_cc_300d',
            # 'min.embed.w2v_cc_300d',
            # 'mk.stopwords',
            # 'mk.lemma',
            # 'mk.embed.w2v_cc_300d',
            # 'ml.stopwords',
            # 'ml.embed.w2v_cc_300d',
            # 'mn.embed.w2v_cc_300d',
            # 'mr.lemma',
            # 'mr.stopwords',
            # 'mr.embed.marathi_bert',
            # 'mr.embed.muril_adapted_local',
            # 'mr.pos',
            # 'ms.embed.w2v_cc_300d',
            # 'mt.lemma',
            # 'mt.pos',
            # 'mt.embed.w2v_cc_300d',
            # 'mwl.embed.w2v_cc_300d',
            # 'my.embed.w2v_cc_300d',
            # 'myv.embed.w2v_cc_300d',
            # 'mzn.embed.w2v_cc_300d',
            # 'nah.embed.w2v_cc_300d',
            # 'nap.embed.w2v_cc_300d',
            # 'nb.stopwords',
            # 'nb.lemma',
            # 'nds.embed.w2v_cc_300d',
            # 'ne.embed.w2v_cc_300d',
            # 'ne.stopwords',
            # 'new.embed.w2v_cc_300d',
            # 'nl.pos.fullstop_dutch_punctuation_prediction',
            # 'nl.stopwords',
            # 'nl.embed.robbert_v2_dutch_base',
            # 'nl.embed.robbertje_1_gb_bort',
            # 'nl.embed.robbertje_1_gb_shuffled',
            # 'nl.embed.robbertje_1_gb_non_shuffled',
            # 'nl.embed.robbertje_1_gb_merged',
            # 'nl.embed.w2v_cc_300d',
            # 'nl.lemma',
            # 'nn.embed.w2v_cc_300d',
            # 'no.lemma',
            # 'no.pos',
            # 'no.pos',
            # 'no.pos',
            # 'no.embed.w2v_cc_300d',
            # 'no.lemma',
            # 'nso.embed.w2v_cc_300d',
            # 'oc.embed.w2v_cc_300d',
            # 'or.embed.w2v_cc_300d',
            # 'orv.lemma',
            # 'os.embed.w2v_cc_300d',
            # 'pa.embed.w2v_cc_300d',
            # 'pa.embed.muril_adapted_local',
            # 'pfl.embed.w2v_cc_300d',
            # 'pl.stopwords',
            # 'pl.embed.w2v_cc_300d',
            # 'pl.lemma',
            # 'pms.embed.w2v_cc_300d',
            # 'pnb.embed.w2v_cc_300d',
            # 'ps.embed.w2v_cc_300d',
            # 'pt.embed.BR_BERTo',
            # 'pt.embed.gs_all',
            # 'pt.stopwords',
            # 'pt.embed.gs_clinical',
            # 'pt.embed.gs_biomedical',
            # 'pt.lemma',
            # 'pt.lemma',
            # 'pt.embed.bert_base_portuguese_cased_finetuned_tcu_acordaos',
            # 'pt.ner.satellite_instrument_roberta_NER',
            # 'pt.embed.bert_small_gl_cased',
            # 'pt.embed.bert_large_cased_pt_lenerbr',
            # 'pt.embed.bert_large_portuguese_cased',
            # 'pt.embed.bert_base_cased_pt_lenerbr',
            # 'pt.embed.bert_base_portuguese_cased_finetuned_peticoes',
            # 'pt.embed.bert_base_portuguese_cased',
            # 'pt.embed.bert_base_pt_cased',
            # 'pt.embed.bert_base_gl_cased',
            # 'qhe.lemma',
            # 'qtd.pos',
            # 'qu.embed.w2v_cc_300d',
            # 'rm.embed.w2v_cc_300d',
            # 'ro.embed.w2v_cc_300d',
            # 'ro.stopwords',
            # 'ro.pos',
            # 'ro.lemma',
            # 'ru.pos',
            # 'ru.lemma',
            # 'ru.lemma',
            # 'ru.embed.ruRoberta_large',
            # 'ru.pos',
            # 'ru.stopwords',
            # 'ru.embed.roberta_base_russian_v0',
            # 'ru.embed.bert_base_ru_cased',
            # 'ru.embed.w2v_cc_300d',
            # 'sa.embed.w2v_cc_300d',
            # 'sa.lemma',
            # 'sa.pos',
            # 'sa.stopwords',
            # 'sah.embed.w2v_cc_300d',
            # 'sc.embed.w2v_cc_300d',
            # 'scn.embed.w2v_cc_300d',
            # 'sco.embed.w2v_cc_300d',
            # 'sd.embed.w2v_cc_300d',
            # 'sh.embed.w2v_cc_300d',
            # 'si.stopwords',
            # 'si.embed.w2v_cc_300d',
            # 'sk.stopwords',
            # 'sk.lemma',
            # 'sk.embed.w2v_cc_300d',
            # 'sl.lemma',
            # 'sl.stopwords',
            # 'sl.pos',
            # 'sl.embed.w2v_cc_300d',
            # 'sme.lemma',
            # 'sme.pos',
            # 'so.embed.w2v_cc_300d',
            # 'sq.stopwords',
            # 'sq.embed.w2v_cc_300d',
            # 'sr.lemma',
            # 'sr.embed.w2v_cc_300d',
            # 'sr.lemma',
            # 'sr.stopwords',
            # 'su.embed.w2v_cc_300d',
            # 'su.embed.sundanese_roberta_base',
            # 'sv.stopwords',
            # 'sv.embed.w2v_cc_300d',
            # 'sv.lemma',
            # 'sv.lemma',
            # 'sw.embed.w2v_cc_300d',
            # 'ta.stopwords',
            # 'ta.embed.w2v_cc_300d',
            # 'ta.embed.muril_adapted_local',
            # 'te.embed.indic_transformers_te_bert',
            # 'te.embed.telugu_bertu',
            # 'te.embed.muril_adapted_local',
            # 'te.embed.indic_transformers_te_roberta',
            # 'te.stopwords',
            # 'te.lemma',
            # 'te.embed.w2v_cc_300d',
            # 'tg.embed.w2v_cc_300d',
            # 'th.stopwords',
            # 'th.embed.w2v_cc_300d',
            # 'ti.stopwords',
            # 'tk.embed.w2v_cc_300d',
            # 'tl.lemma',
            # 'tl.embed.w2v_cc_300d',
            # 'tl.stopwords',
            # 'tl.embed.roberta_tagalog_large',
            # 'tl.embed.roberta_tagalog_base',
            # 'tn.stopwords',
            # 'tr.lemma',
            # 'tr.stopwords',
            # 'tr.lemma',
            # 'tr.pos',
            # 'tr.embed.w2v_cc_300d',
            # 'tr.lemma',
            # 'tr.pos',
            # 'tr.pos',
            # 'tr.lemma',
            # 'tr.lemma',
            # 'tt.stopwords',
            # 'tt.embed.w2v_cc_300d',
            # 'ug.embed.w2v_cc_300d',
            # 'uk.embed.ukr_roberta_base',
            # 'uk.stopwords',
            # 'uk.embed.w2v_cc_300d',
            # 'uk.pos.bert_large_slavic_cyrillic_upos',
            # 'uk.pos.bert_base_slavic_cyrillic_upos',
            # 'ur.embed.muril_adapted_local',
            # 'ur.embed.roberta_urdu_small',
            # 'ur.lemma',
            # 'ur.lemma',
            # 'ur.pos',
            # 'ur.embed.w2v_cc_300d',
            # 'ur.stopwords',
            # 'uz.embed.w2v_cc_300d',
            # 'vec.embed.w2v_cc_300d',
            # 'vi.stopwords',
            # 'vi.embed.w2v_cc_300d',
            # 'vls.embed.w2v_cc_300d',
            # 'vo.embed.w2v_cc_300d',
            # 'wa.embed.w2v_cc_300d',
            # 'war.embed.w2v_cc_300d',
            # 'wo.pos',
            # 'xmf.embed.w2v_cc_300d',
            # 'yi.embed.w2v_cc_300d',
            # 'yo.embed.w2v_cc_300d',
            # 'zea.embed.w2v_cc_300d',
            # 'zh.embed.wobert_chinese_plus_base',
            # 'zh.embed.bert_base_chinese_jinyong',
            # 'zh.embed.rbt3',
            # 'zh.embed.jdt_fin_roberta_wwm',
            # 'zh.embed.mengzi_oscar_base',
            # 'zh.embed.roberta_base_wechsel_chinese',
            # 'zh.embed.sikubert',
            # 'zh.embed.jdt_fin_roberta_wwm_large',
            # 'zh.embed.rbtl3',
            # 'zh.embed.macbert4csc_base_chinese',
            # 'zh.pos.chinese_roberta_large_upos',
            # 'zh.pos.chinese_roberta_base_upos',
            # 'zh.pos.chinese_bert_wwm_ext_upos',
            # 'zh.pos',
            # 'zh.stopwords',
            # 'zh.pos.bert_base_chinese_pos',
            # 'zh.embed.rbt6',
            # 'zh.embed.sikuroberta',
            # 'zh.embed.uer_large',
            # 'zh.embed.env_bert_chinese',
            # 'zh.embed.chinese_roberta_wwm_ext',
            # 'zh.embed.chinese_macbert_base',
            # 'zh.embed.bert_base_zh_cased',
            # 'zh.embed.bert_large_chinese',
            # 'zh.embed.chinese_roberta_wwm_large_ext_fix_mlm',
            # 'zh.embed.chinese_roberta_wwm_ext_large',
            # 'zh.embed.chinese_bert_wwm_ext',
            # 'zh.embed.chinese_macbert_large',
            # 'zh.embed.mengzi_oscar_base_retrieval',
            # 'zh.embed.mengzi_bert_base_fin',
            # 'zh.embed.wobert_chinese_base',
            # 'zh.embed.wobert_chinese_plus',
            # 'zh.embed.rbt4',
            # 'zh.embed.mengzi_oscar_base_caption',
            # 'zh.embed.mengzi_bert_base',
            # 'zh.embed.w2v_cc_300d',


            # 'bs.embed.w2v_cc_300d', # TODO BAD?!?!
            # 'nl.embed.MedRoBERTa' # BAD!

        ]

        fails = []
        fail_insta = True
        for t in te:
            try:
                print(f'Testing spell = {t}')
                pipe = nlu.load(t, verbose=True)
                df = pipe.predict(['Peter love pancaces. I hate Mondays', 'I love Fridays'])
                for c in df.columns: print(df[c])
            except Exception as err:
                print(f'Failure for spell = {t} ', err)
                e = sys.exc_info()
                print(e[0])
                print(e[1])
                fails.append(t)
                if fail_insta :
                    raise Exception(err)
        fail_string = "\n".join(fails)
        print(f'Done testing, failures = {fail_string}')
        if len(fails) > 0:
            raise Exception("Not all new spells completed successfully")

    def test_344_HC_models(self):
        import tests.secrets as sct

        SPARK_NLP_LICENSE = sct.SPARK_NLP_LICENSE
        AWS_ACCESS_KEY_ID = sct.AWS_ACCESS_KEY_ID
        AWS_SECRET_ACCESS_KEY = sct.AWS_SECRET_ACCESS_KEY
        JSL_SECRET = sct.JSL_SECRET
        nlu.auth(SPARK_NLP_LICENSE, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, JSL_SECRET)
        te = [
            'en.med_ner.biomedical_bc2gm', # OK?
            'en.resolve.rxnorm_action_treatment', # OK?

            # 'en.classify.rct_binary.use', # BAD
            # 'en.classify.rct_binary.biobert', # BAD
            'pt.med_ner.deid.subentity',
            'pt.med_ner.deid.generic',
            'pt.med_ner.deid',
        ]
        sample_texts = ["""
            Antonio Pérez Juan, nacido en Cadiz, España. Aún no estaba vacunado, se infectó con Covid-19 el dia 14/03/2020 y tuvo que ir al Hospital. Fue tratado con anticuerpos monoclonales en la Clinica San Carlos..
                        """,
                        """
                        Datos del paciente. Nombre:  Jose . Apellidos: Aranda Martinez. NHC: 2748903. NASS: 26 37482910.
                        """,
                        """The patient was given metformin 500 mg, 2.5 mg of coumadin and then ibuprofen""",
                        """he patient was given metformin 400 mg, coumadin 5 mg, coumadin, amlodipine 10 MG""",
                        """To compare the results of recording enamel opacities using the TF and modified DDE indices.""",
                        """I felt a bit drowsy and had blurred vision after taking Aspirin.""",
                        ]
        fails = []
        succs = []
        fail_insta = True
        for t in te:

            try:
                print(f'Testing spell = {t}')
                pipe = nlu.load(t, verbose=True)
                df = pipe.predict(sample_texts, drop_irrelevant_cols=False, metadata=True, )
                print(df.columns)
                for c in df.columns:
                    print(df[c])
                succs.append(t)
            except Exception as err:
                print(f'Failure for spell = {t} ', err)
                fails.append(t)
                if fail_insta:
                    break
        fail_string = '\n'.join(fails)
        succ_string = '\n'.join(succs)
        print(f'Done testing, failures = {fail_string}')
        print(f'Done testing, successes = {succ_string}')
        if len(fails) > 0:
            raise Exception("Not all new spells completed successfully")




if __name__ == '__main__':
    unittest.main()
