{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rBXrqlGEYA8G"
   },
   "source": [
    "# Lemmatization with NLU \n",
    "\n",
    "Lemmatizing returns the base form, the so called lemma of every token in the input data.    \n",
    "\n",
    "I. e. 'He was hungry' becomes 'He be hungry'\n",
    "\n",
    "The Lemmatizer works by operating on a dictionary and taking context into account. This lets the Lemmatizer dervie a different base word for for a word in two different contexts which depends on the Part of Speech tags. \n",
    "\n",
    "\n",
    "\n",
    "This is the main difference  to Stemming, which solves the same problem by applying a heuristic process that removes the end of words.\n",
    "\n",
    "\n",
    "# 1. Install Java and NLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-09-17T16:41:50.831806Z",
     "iopub.status.busy": "2020-09-17T16:41:50.830093Z",
     "iopub.status.idle": "2020-09-17T16:42:09.783893Z",
     "shell.execute_reply": "2020-09-17T16:42:09.783257Z"
    },
    "executionInfo": {
     "elapsed": 66399,
     "status": "ok",
     "timestamp": 1600189722396,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "M2-GiYL6xurJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\r\n",
      "E: Unable to lock directory /var/lib/apt/lists/\r\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\r\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\r\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\r\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "! apt-get update -qq > /dev/null   \n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! pip install nlu  > /dev/null    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N_CL8HZ8Ydry"
   },
   "source": [
    "## 2. Load Model and lemmatize sample string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-09-17T16:42:09.788209Z",
     "iopub.status.busy": "2020-09-17T16:42:09.787625Z",
     "iopub.status.idle": "2020-09-17T16:42:34.736212Z",
     "shell.execute_reply": "2020-09-17T16:42:34.737391Z"
    },
    "executionInfo": {
     "elapsed": 96858,
     "status": "ok",
     "timestamp": 1600189752944,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "j2ZZZvr1uGpx",
    "outputId": "2bd35062-697d-45d4-b757-7a7e41dd889e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[He, be, suprise, by, the, diversity, of, NLU]</td>\n",
       "      <td>He was suprised by the diversity of NLU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       lemma  \\\n",
       "origin_index                                                   \n",
       "0             [He, be, suprise, by, the, diversity, of, NLU]   \n",
       "\n",
       "                                             sentence  \n",
       "origin_index                                           \n",
       "0             He was suprised by the diversity of NLU  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nlu\n",
    "pipe = nlu.load('en.lemma')\n",
    "pipe.predict('He was suprised by the diversity of NLU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRSEzc-RCceu"
   },
   "source": [
    "# 3. Get one row per lemmatized token by setting outputlevel to token.    \n",
    "This lets us compare what the original token was and what it was lemmatized to to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-09-17T16:42:34.745889Z",
     "iopub.status.busy": "2020-09-17T16:42:34.744456Z",
     "iopub.status.idle": "2020-09-17T16:42:36.316778Z",
     "shell.execute_reply": "2020-09-17T16:42:36.316238Z"
    },
    "executionInfo": {
     "elapsed": 98006,
     "status": "ok",
     "timestamp": 1600189754119,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "9bujAZtOCfRW",
    "outputId": "57b52d50-2121-48b1-9d23-683ecf99a8c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He</td>\n",
       "      <td>He</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>suprise</td>\n",
       "      <td>suprised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diversity</td>\n",
       "      <td>diversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLU</td>\n",
       "      <td>NLU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  lemma      token\n",
       "origin_index                      \n",
       "0                    He         He\n",
       "0                    be        was\n",
       "0               suprise   suprised\n",
       "0                    by         by\n",
       "0                   the        the\n",
       "0             diversity  diversity\n",
       "0                    of         of\n",
       "0                   NLU        NLU"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict('He was suprised by the diversity of NLU', output_level='token')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "av7EiK4adb24"
   },
   "source": [
    "# 4. Checkout the Lemma models NLU has to offer for other languages than English!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-09-17T16:42:36.321906Z",
     "iopub.status.busy": "2020-09-17T16:42:36.321310Z",
     "iopub.status.idle": "2020-09-17T16:42:36.330354Z",
     "shell.execute_reply": "2020-09-17T16:42:36.329728Z"
    },
    "executionInfo": {
     "elapsed": 97922,
     "status": "ok",
     "timestamp": 1600189754121,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "hZ8xLHY7dgJ8",
    "outputId": "0e7ae09b-5f58-4153-f607-f1bcaf8cb608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For language <nl> NLU provides the following Models : \n",
      "nlu.load('nl.lemma') returns Spark NLP model lemma\n",
      "For language <en> NLU provides the following Models : \n",
      "nlu.load('en.lemma') returns Spark NLP model lemma_antbnc\n",
      "nlu.load('en.lemma.antbnc') returns Spark NLP model lemma_antbnc\n",
      "For language <fr> NLU provides the following Models : \n",
      "nlu.load('fr.lemma') returns Spark NLP model lemma\n",
      "For language <de> NLU provides the following Models : \n",
      "nlu.load('de.lemma') returns Spark NLP model lemma\n",
      "For language <it> NLU provides the following Models : \n",
      "nlu.load('it.lemma') returns Spark NLP model lemma_dxc\n",
      "nlu.load('it.lemma.dxc') returns Spark NLP model lemma_dxc\n",
      "For language <nb> NLU provides the following Models : \n",
      "nlu.load('nb.lemma') returns Spark NLP model lemma\n",
      "For language <pl> NLU provides the following Models : \n",
      "nlu.load('pl.lemma') returns Spark NLP model lemma\n",
      "For language <pt> NLU provides the following Models : \n",
      "nlu.load('pt.lemma') returns Spark NLP model lemma\n",
      "For language <ru> NLU provides the following Models : \n",
      "nlu.load('ru.lemma') returns Spark NLP model lemma\n",
      "For language <es> NLU provides the following Models : \n",
      "nlu.load('es.lemma') returns Spark NLP model lemma\n",
      "For language <hy> NLU provides the following Models : \n",
      "nlu.load('hy.lemma') returns Spark NLP model lemma\n",
      "For language <eu> NLU provides the following Models : \n",
      "nlu.load('eu.lemma') returns Spark NLP model lemma\n",
      "For language <br> NLU provides the following Models : \n",
      "nlu.load('br.lemma') returns Spark NLP model lemma\n",
      "For language <bg> NLU provides the following Models : \n",
      "nlu.load('bg.lemma') returns Spark NLP model lemma\n",
      "For language <ca> NLU provides the following Models : \n",
      "nlu.load('ca.lemma') returns Spark NLP model lemma\n",
      "For language <cs> NLU provides the following Models : \n",
      "nlu.load('cs.lemma') returns Spark NLP model lemma\n",
      "For language <fi> NLU provides the following Models : \n",
      "nlu.load('fi.lemma') returns Spark NLP model lemma\n",
      "For language <gl> NLU provides the following Models : \n",
      "nlu.load('gl.lemma') returns Spark NLP model lemma\n",
      "For language <el> NLU provides the following Models : \n",
      "nlu.load('el.lemma') returns Spark NLP model lemma\n",
      "For language <hi> NLU provides the following Models : \n",
      "nlu.load('hi.lemma') returns Spark NLP model lemma\n",
      "For language <hu> NLU provides the following Models : \n",
      "nlu.load('hu.lemma') returns Spark NLP model lemma\n",
      "For language <id> NLU provides the following Models : \n",
      "nlu.load('id.lemma') returns Spark NLP model lemma\n",
      "For language <ga> NLU provides the following Models : \n",
      "nlu.load('ga.lemma') returns Spark NLP model lemma\n",
      "For language <da> NLU provides the following Models : \n",
      "nlu.load('da.lemma') returns Spark NLP model lemma\n",
      "For language <la> NLU provides the following Models : \n",
      "nlu.load('la.lemma') returns Spark NLP model lemma\n",
      "For language <lv> NLU provides the following Models : \n",
      "nlu.load('lv.lemma') returns Spark NLP model lemma\n",
      "For language <mr> NLU provides the following Models : \n",
      "nlu.load('mr.lemma') returns Spark NLP model lemma\n",
      "For language <ro> NLU provides the following Models : \n",
      "nlu.load('ro.lemma') returns Spark NLP model lemma\n",
      "For language <sk> NLU provides the following Models : \n",
      "nlu.load('sk.lemma') returns Spark NLP model lemma\n",
      "For language <sl> NLU provides the following Models : \n",
      "nlu.load('sl.lemma') returns Spark NLP model lemma\n",
      "For language <sv> NLU provides the following Models : \n",
      "nlu.load('sv.lemma') returns Spark NLP model lemma\n",
      "For language <tr> NLU provides the following Models : \n",
      "nlu.load('tr.lemma') returns Spark NLP model lemma\n",
      "For language <uk> NLU provides the following Models : \n",
      "nlu.load('uk.lemma') returns Spark NLP model lemma\n",
      "For language <yo> NLU provides the following Models : \n",
      "nlu.load('yo.lemma') returns Spark NLP model lemma\n"
     ]
    }
   ],
   "source": [
    "nlu.print_all_model_kinds_for_action('lemma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TsRxB950elTp"
   },
   "source": [
    "## 4.1 Let's try German lematization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2020-09-17T16:42:36.335046Z",
     "iopub.status.busy": "2020-09-17T16:42:36.334204Z",
     "iopub.status.idle": "2020-09-17T16:42:46.370111Z",
     "shell.execute_reply": "2020-09-17T16:42:46.370583Z"
    },
    "executionInfo": {
     "elapsed": 108276,
     "status": "ok",
     "timestamp": 1600189764551,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "5d_J7-20dvCw",
    "outputId": "137337bf-0371-4edb-bfc7-9c2904fe4d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma download started this may take some time.\n",
      "Approximate size to download 4 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Er</td>\n",
       "      <td>Er</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sein</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>von</td>\n",
       "      <td>von</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>der</td>\n",
       "      <td>der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vielfältigkeit</td>\n",
       "      <td>Vielfältigkeit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>der</td>\n",
       "      <td>des</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLU</td>\n",
       "      <td>NLU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Packets</td>\n",
       "      <td>Packets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>begeistern</td>\n",
       "      <td>begeistert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       lemma           token\n",
       "origin_index                                \n",
       "0                         Er              Er\n",
       "0                       sein             war\n",
       "0                        von             von\n",
       "0                        der             der\n",
       "0             Vielfältigkeit  Vielfältigkeit\n",
       "0                        der             des\n",
       "0                        NLU             NLU\n",
       "0                    Packets         Packets\n",
       "0                 begeistern      begeistert"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlu.load('de.lemma').predict(\"Er war von der Vielfältigkeit des NLU Packets begeistert\",output_level='token')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM0xowzteZ9r4NKeKILO13b",
   "collapsed_sections": [],
   "name": "NLU - Lemmatization .ipynb",
   "provenance": [
    {
     "file_id": "1pgqoRJ6yGWbTLWdLnRvwG5DLSU3rxuMq",
     "timestamp": 1599401652794
    },
    {
     "file_id": "1JrlfuV2jNGTdOXvaWIoHTSf6BscDMkN7",
     "timestamp": 1599401257319
    },
    {
     "file_id": "1svpqtC3cY6JnRGeJngIPl2raqxdowpyi",
     "timestamp": 1599400881246
    },
    {
     "file_id": "1tW833T3HS8F5Lvn6LgeDd5LW5226syKN",
     "timestamp": 1599398724652
    },
    {
     "file_id": "1CYzHfQyFCdvIOVO2Z5aggVI9c0hDEOrw",
     "timestamp": 1599354735581
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
