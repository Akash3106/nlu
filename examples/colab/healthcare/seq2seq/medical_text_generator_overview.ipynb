{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/seq2seq/medical_text_generator_overview.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Medical Text Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MedicalTextGenerator uses the basic BioGPT model to perform various tasks related to medical text abstraction. With this annotator, a user can provide a prompt and context and instruct the system to perform a specific task, such as explaining why a patient may have a particular disease or paraphrasing the context more directly. In addition, this annotator can create a clinical note for a cancer patient using the given keywords or write medical texts based on introductory sentences. The BioGPT model is trained on large volumes of medical data allowing it to identify and extract the most relevant information from the text provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All the models avaiable are :**\n",
    "\n",
    "| Language | nlu.load() reference                                    | Spark NLP Model reference                                                                                                         |\n",
    "|----------|---------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|\n",
    "| English  | en.text_generator.biomedical_biogpt_base | [text_generator_biomedical_biogpt_base](https://nlp.johnsnowlabs.com//2023/04/03/text_generator_biomedical_biogpt_base_en.html) |\n",
    "| English  | en.text_generator.generic_flan_base      | [text_generator_generic_flan_base](https://nlp.johnsnowlabs.com//2023/04/03/text_generator_generic_flan_base_en.html)           |\n",
    "| English  | en.text_generator.generic_jsl_base       | [text_generator_generic_jsl_base](https://nlp.johnsnowlabs.com//2023/04/03/text_generator_generic_jsl_base_en.html)             |\n",
    "| English  | en.text_generator.generic_flan_t5_large  | [text_generator_generic_flan_t5_large](https://nlp.johnsnowlabs.com//2023/04/04/text_generator_generic_flan_t5_large_en.html)   |\n",
    "| English  | en.text_generator.biogpt_chat_jsl                       | [biogpt_chat_jsl](https://nlp.johnsnowlabs.com//2023/04/12/biogpt_chat_jsl_en.html)                                             |\n",
    "| English  | en.text_generator.biogpt_chat_jsl_conversational        | [biogpt_chat_jsl_conversational](https://nlp.johnsnowlabs.com//2023/04/18/biogpt_chat_jsl_conversational_en.html)               |\n",
    "| English  | en.text_generator.biogpt_chat_jsl_conditions            | [biogpt_chat_jsl_conditions](https://nlp.johnsnowlabs.com//2023/05/11/biogpt_chat_jsl_conditions_en.html)                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# !wget http://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash\n",
    "import nlu\n",
    "\n",
    "\n",
    "SPARK_NLP_LICENSE = \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJleHAiOjE3MDQwNjcyMDAsImlhdCI6MTY3Mjk2MzIwMCwidW5pcXVlX2lkIjoiZGQ0MzE4ZTYtOGRhOS0xMWVkLTgyNjAtY2ViMjJiMTM3OTk4Iiwic2NvcGUiOlsibGVnYWw6aW5mZXJlbmNlIiwibGVnYWw6dHJhaW5pbmciLCJmaW5hbmNlOmluZmVyZW5jZSIsImZpbmFuY2U6dHJhaW5pbmciLCJvY3I6aW5mZXJlbmNlIiwib2NyOnRyYWluaW5nIiwiaGVhbHRoY2FyZTppbmZlcmVuY2UiLCJoZWFsdGhjYXJlOnRyYWluaW5nIl19.Uw5z6ihpLukV9sBVZn4SRZmgshmLaIFHc_KqNGKejS7Yj4b3m0pM7FMRBx2BJ5rzIPQJD0P0Qv-vK42Ze71BS4_TDe0r52UltmxX0K1R4ijUbK3gA0qYJMSRZnFSKIocZ7TRxXcACJeHsqnMkp6um0D7abrdKMSdzEM87TAOX0sO8H29rhW8UKz5eiE3o45hMMcYuxFv5zbJr9X7pxZkbVmI72Mbq8Pq0PXzKIct1S85IhKo22tlhgGeo_CLGZkDsM9735QiBTqZ8olX5sFpqTy4cDMuoX5odR8VBumf37w80NYEIZlt_vOWaXEgWvYGDhjYxJ-YbUv0bT9kQ4TmHA\"\n",
    "AWS_ACCESS_KEY_ID = \"AKIASRWSDKBGPGIFTRDC\"\n",
    "AWS_SECRET_ACCESS_KEY = \"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\"\n",
    "JSL_SECRET = \"4.4.3-d6a8f771226d032db7dccc1eae0635d5fe68d696\"\n",
    "\n",
    "nlu.auth(SPARK_NLP_LICENSE,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,JSL_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‘  **en.text_generator.biomedical_biogpt_base**\n",
    "\n",
    "This model is a BioGPT (LLM) based text generation model that is finetuned with biomedical datasets (Pubmed abstracts) by John Snow Labs. Â Given a few tokens as an intro, it can generate human-like, conceptually meaningful texts Â up to 1024 tokens given an input text (max 1024 tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-13T17:39:58.806233400Z",
     "start_time": "2023-07-13T17:37:10.582507500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Warning::Spark Session already created, some configs may not take.\n",
      "text_generator_biomedical_biogpt_base download started this may take some time.\n",
      "[OK!]\n",
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 354.6 KB\n",
      "[OK!]\n",
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_31212\\46330883.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mnlu\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'en.text_generator.biomedical_biogpt_base'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Covid 19 is'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mF:\\Work\\repos\\nlu\\nlu\\pipe\\pipeline.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, data, output_level, positions, keep_stranger_features, metadata, multithread, drop_irrelevant_cols, return_spark_df, get_embeddings)\u001B[0m\n\u001B[0;32m    464\u001B[0m         \u001B[1;33m:\u001B[0m\u001B[0mparam\u001B[0m \u001B[0mget_embeddings\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mWhether\u001B[0m \u001B[0mto\u001B[0m \u001B[1;32mreturn\u001B[0m \u001B[0membeddings\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;32mnot\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    465\u001B[0m         \u001B[1;33m:\u001B[0m\u001B[1;32mreturn\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    466\u001B[0m         '''\n\u001B[0;32m    467\u001B[0m         \u001B[1;32mfrom\u001B[0m \u001B[0mnlu\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpipe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict_helper\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0m__predict__\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 468\u001B[1;33m         return __predict__(self, data, output_level, positions, keep_stranger_features, metadata, multithread,\n\u001B[0m\u001B[0;32m    469\u001B[0m                            drop_irrelevant_cols, return_spark_df, get_embeddings)\n",
      "\u001B[1;32mF:\\Work\\repos\\nlu\\nlu\\pipe\\utils\\predict_helper.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(pipe, data, output_level, positions, keep_stranger_features, metadata, multithread, drop_irrelevant_cols, return_spark_df, get_embeddings)\u001B[0m\n\u001B[0;32m    162\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mpipe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_fitted\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    163\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mpipe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhas_trainable_components\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    164\u001B[0m             \u001B[0mpipe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 166\u001B[1;33m             \u001B[0mpipe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    167\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    168\u001B[0m     \u001B[0mpipe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__configure_light_pipe_usage__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDataConversionUtils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize_of\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmultithread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    169\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\Work\\repos\\nlu\\nlu\\pipe\\pipeline.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, dataset, dataset_path, label_seperator)\u001B[0m\n\u001B[0;32m    198\u001B[0m             \u001B[1;31m# fit on empty dataframe since no data provided\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    199\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_fitted\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    200\u001B[0m                 logger.info(\n\u001B[0;32m    201\u001B[0m                     'Fitting on empty Dataframe, could not infer correct training method. This is intended for non-trainable pipelines.')\n\u001B[1;32m--> 202\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvanilla_transformer_pipe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspark_estimator_pipe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_sample_spark_dataframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    203\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlight_transformer_pipe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLightPipeline\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvanilla_transformer_pipe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    205\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhas_trainable_components\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mF:\\Work\\repos\\nlu\\nlu\\pipe\\pipeline.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget_sample_spark_dataframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     99\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"text\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'This day sucks'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'I love this day'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'I dont like Sami'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    100\u001B[0m         \u001B[0mtext_df\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 101\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msparknlp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreateDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtext_df\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\miniconda3\\envs\\nlu\\lib\\site-packages\\pyspark\\sql\\session.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[0;32m    669\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    670\u001B[0m             \u001B[0mhas_pandas\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    671\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mhas_pandas\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpandas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    672\u001B[0m             \u001B[1;31m# Create a DataFrame from pandas DataFrame.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 673\u001B[1;33m             return super(SparkSession, self).createDataFrame(\n\u001B[0m\u001B[0;32m    674\u001B[0m                 data, schema, samplingRatio, verifySchema)\n\u001B[0;32m    675\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_dataframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\nlu\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, data, schema, samplingRatio, verifySchema)\u001B[0m\n\u001B[0;32m    295\u001B[0m                         \u001B[1;34m\"fallback with 'spark.sql.execution.arrow.pyspark.fallback.enabled' \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    296\u001B[0m                         \"has been set to false.\\n  %s\" % str(e))\n\u001B[0;32m    297\u001B[0m                     \u001B[0mwarnings\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwarn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    298\u001B[0m                     \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 299\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_convert_from_pandas\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimezone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    300\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_dataframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mschema\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msamplingRatio\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverifySchema\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\nlu\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, pdf, schema, timezone)\u001B[0m\n\u001B[0;32m    327\u001B[0m                                 \u001B[0mpdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    328\u001B[0m                                 \u001B[0mcopied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    329\u001B[0m                             \u001B[0mpdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mfield\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0ms\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    330\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 331\u001B[1;33m                 \u001B[1;32mfor\u001B[0m \u001B[0mcolumn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mseries\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miteritems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    332\u001B[0m                     \u001B[0ms\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_series_convert_timestamps_tz_local\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseries\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtimezone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    333\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[0ms\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mseries\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    334\u001B[0m                         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mcopied\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\miniconda3\\envs\\nlu\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5985\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mname\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_accessors\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5986\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5987\u001B[0m         ):\n\u001B[0;32m   5988\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5989\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "nlu.load('en.text_generator.biomedical_biogpt_base').predict('Covid 19 is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
